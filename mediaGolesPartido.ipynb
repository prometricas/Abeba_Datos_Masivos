{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDyXBVVcUk2CWX9OWcccSw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prometricas/Abeba_Datos_Masivos/blob/main/mediaGolesPartido.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Instalación de Java y Hadoop**"
      ],
      "metadata": {
        "id": "yJHa4RzjhMa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instalar JDK de Java**"
      ],
      "metadata": {
        "id": "GQg7tQjVuobh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y openjdk-11-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "82PB4Zodu93s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instalar Hadoop**"
      ],
      "metadata": {
        "id": "84JwNdLxwgQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar Hadoop\n",
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoFWj1DUwuPz",
        "outputId": "0d2f2a80-8b40-479b-c632-9bef3f0c295b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-11 15:45:49--  https://downloads.apache.org/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.208.237, 135.181.214.104, 2a01:4f8:10a:39da::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.208.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1065831750 (1016M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.4.2.tar.gz’\n",
            "\n",
            "hadoop-3.4.2.tar.gz 100%[===================>]   1016M  25.9MB/s    in 41s     \n",
            "\n",
            "2026-01-11 15:46:31 (24.7 MB/s) - ‘hadoop-3.4.2.tar.gz’ saved [1065831750/1065831750]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomprimir y mover a carpeta de usuario\n",
        "!tar -xzf hadoop-3.4.2.tar.gz\n",
        "!mv hadoop-3.4.2/ /usr/local/\n",
        "\n",
        "# Mostrar los archivos de carpeta local:\n",
        "!ls /usr/local"
      ],
      "metadata": {
        "id": "QxAAWIYeI6KP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65909cc-9e1e-4759-99ba-b41cf21b6242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    dist_metrics.pxd  games\t       include\tlibexec     man  sbin\tsrc\n",
            "colab  etc\t\t hadoop-3.4.2  lib\tLICENSE.md  opt  share\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Definir variables de entorno**\n"
      ],
      "metadata": {
        "id": "8tm2Ds-HJ6bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.4.2\"\n",
        "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/hadoop-3.4.2/bin\"\n",
        "!hadoop version"
      ],
      "metadata": {
        "id": "bl45zkpNKHI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbcc76d4-975d-4a01-c018-3ce1e6d38afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hadoop 3.4.2\n",
            "Source code repository https://github.com/apache/hadoop.git -r 84e8b89ee2ebe6923691205b9e171badde7a495c\n",
            "Compiled by ahmarsu on 2025-08-20T10:30Z\n",
            "Compiled on platform linux-x86_64\n",
            "Compiled with protoc 3.23.4\n",
            "From source with checksum fa94c67d4b4be021b9e9515c9b0f7b6\n",
            "This command was run using /usr/local/hadoop-3.4.2/share/hadoop/common/hadoop-common-3.4.2.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. `Importar base de datos`**"
      ],
      "metadata": {
        "id": "15V6Nt-khqRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar archivo\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Verificar\n",
        "!ls -lah\n",
        "!head -n 5 resultados_futbol.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "collapsed": true,
        "id": "uSQQLZH4h7mM",
        "outputId": "6edd6dde-8461-4021-e04b-9a1624573dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-41acc592-dbed-489e-9259-e43bb0a61a58\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-41acc592-dbed-489e-9259-e43bb0a61a58\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resultados_futbol.csv to resultados_futbol.csv\n",
            "total 1018M\n",
            "drwxr-xr-x 1 root root  4.0K Jan 11 15:47 .\n",
            "drwxr-xr-x 1 root root  4.0K Jan 11 15:32 ..\n",
            "-rw-r--r-- 1 root root   861 Jan 11 15:41 combinerMediaGolesPartido.py\n",
            "drwxr-xr-x 4 root root  4.0K Dec 11 14:34 .config\n",
            "-rw-r--r-- 1 root root 1017M Oct  4 09:30 hadoop-3.4.2.tar.gz\n",
            "-rw-r--r-- 1 root root   978 Jan 11 15:41 mapperMediaGolesPartido.py\n",
            "-rw-r--r-- 1 root root  1.3K Jan 11 15:43 reducerMediaGolesPartido.py\n",
            "-rw-r--r-- 1 root root  557K Jan 11 15:47 resultados_futbol.csv\n",
            "drwxr-xr-x 1 root root  4.0K Dec 11 14:34 sample_data\n",
            ",Season,Game,Score,Teams,Home Team,Away Team\n",
            "0,2000-2001,1,1-2,Mallorca - Real Madrid,Mallorca,Real Madrid\n",
            "1,2000-2001,1,1-2,Valencia - Racing,Valencia,Racing\n",
            "2,2000-2001,1,1-0,Athletic - Real Betis,Athletic,Real Betis\n",
            "3,2000-2001,1,0-2,Atlético - Rayo Vallecano,Atlético,Rayo Vallecano\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Crear scripts: *Mapper, Combiner, Reducer***\n"
      ],
      "metadata": {
        "id": "W0ch-yv0j4ia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mapper**\n",
        "Emite por partido dos claves:\n",
        "- **equipo|Local** con *(goles_local, 1)*\n",
        "- **equipo|Visitante** con *(goles_visitante, 1)*\n",
        "\n",
        "Usa una clave compuesta con '|' para que todo quede agrupado sin configurar separadores especiales.\n"
      ],
      "metadata": {
        "id": "riFd5TgFlIoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mapperMediaGolesPartido.py\n",
        "#!/usr/bin/python3\n",
        "import sys\n",
        "import csv\n",
        "import re\n",
        "\n",
        "pat_equipo = re.compile(r\"\\s*[-–]\\s*\")\n",
        "\n",
        "for linea in sys.stdin:\n",
        "    linea = linea.strip()\n",
        "    if not linea:\n",
        "        continue\n",
        "\n",
        "    fila = next(csv.reader([linea]))\n",
        "\n",
        "    if len(fila) >= 2 and fila[1].strip().lower() == \"season\":\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        if len(fila) >= 7:\n",
        "            score = fila[3].strip()\n",
        "            local = fila[5].strip()\n",
        "            visita = fila[6].strip()\n",
        "        elif len(fila) >= 4:\n",
        "            score = fila[2].strip()\n",
        "            equipos = fila[3].strip()\n",
        "            partes = pat_equipo.split(equipos, maxsplit=1)\n",
        "            if len(partes) != 2:\n",
        "                continue\n",
        "            local, visita = partes[0].strip(), partes[1].strip()\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        g_local, g_visita = [int(x.strip()) for x in score.split(\"-\", 1)]\n",
        "\n",
        "        print(f\"{local}|Local\\t{g_local}\\t1\")\n",
        "        print(f\"{visita}|Visitante\\t{g_visita}\\t1\")\n",
        "\n",
        "    except Exception:\n",
        "        continue\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW1W0mlvkdcb",
        "outputId": "0b413329-e4f4-42f5-a549-bccbfa68600f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mapperMediaGolesPartido.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Combiner**\n",
        "* Acumula por clave **equipo|condición** las sumas de goles y la cantidad de partidos.\n",
        "* Nunca calculo el promedio aquí, porque el promedio no es asociativo para combinar.\n",
        "\n"
      ],
      "metadata": {
        "id": "GqUo2sfnkSc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile combinerMediaGolesPartido.py\n",
        "#!/usr/bin/python3\n",
        "import sys\n",
        "\n",
        "clave_actual = None\n",
        "goles_acum = 0\n",
        "partidos_acum = 0\n",
        "\n",
        "for linea in sys.stdin:\n",
        "    linea = linea.strip()\n",
        "    if not linea:\n",
        "        continue\n",
        "\n",
        "    partes = linea.split(\"\\t\")\n",
        "    if len(partes) < 3:\n",
        "        continue\n",
        "\n",
        "    clave = partes[0]\n",
        "    try:\n",
        "        goles = int(partes[1])\n",
        "        partidos = int(partes[2])\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "    if clave_actual is None:\n",
        "        clave_actual = clave\n",
        "        goles_acum = goles\n",
        "        partidos_acum = partidos\n",
        "        continue\n",
        "\n",
        "    if clave == clave_actual:\n",
        "        goles_acum += goles\n",
        "        partidos_acum += partidos\n",
        "    else:\n",
        "        print(f\"{clave_actual}\\t{goles_acum}\\t{partidos_acum}\")\n",
        "        clave_actual = clave\n",
        "        goles_acum = goles\n",
        "        partidos_acum = partidos\n",
        "\n",
        "if clave_actual is not None:\n",
        "    print(f\"{clave_actual}\\t{goles_acum}\\t{partidos_acum}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJqOJkcXlpYn",
        "outputId": "3df567fa-a77b-478d-8865-488657979e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing combinerMediaGolesPartido.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reducer**\n",
        "* Suma goles y partidos por clave **equipo|condición** y calculo la media final.\n",
        "* Yo emito: **equipo;condición;mediagoles**\n",
        "* En este script, se ajusta el cálculo del promedio a números enteros aquí. Se hace aquí porque es donde más conviene por eficiencia, ya que *mapper* y *combiner* siguen trabajando con enteros (sumas) y en el *reducer* calculo el promedio final una sola vez por clave, evitando formateos/decimales: menos operaciones por registro.\n",
        "\n"
      ],
      "metadata": {
        "id": "J4vra2ojkU8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reducerMediaGolesPartido.py\n",
        "#!/usr/bin/python3\n",
        "import sys\n",
        "\n",
        "\"\"\"\n",
        "Reducer: mediaGolesPartido (salida entera)\n",
        "Yo sumo goles y partidos por clave equipo|condición y calculo la media final como entero.\n",
        "Yo redondeo al entero más cercano usando solo aritmética entera para hacerlo más rápido.\n",
        "Yo emito: equipo;condición;mediagoles\n",
        "\"\"\"\n",
        "\n",
        "clave_actual = None\n",
        "goles_acum = 0\n",
        "partidos_acum = 0\n",
        "\n",
        "def emitir_resultado(clave, goles, partidos):\n",
        "    if partidos <= 0:\n",
        "        media_entera = 0\n",
        "    else:\n",
        "        # Yo hago redondeo al entero más cercano sin usar float: (goles + partidos/2) / partidos\n",
        "        media_entera = (goles + (partidos // 2)) // partidos\n",
        "\n",
        "    equipo, condicion = clave.split(\"|\", 1)\n",
        "    print(f\"{equipo};{condicion};{media_entera}\")\n",
        "\n",
        "for linea in sys.stdin:\n",
        "    linea = linea.strip()\n",
        "    if not linea:\n",
        "        continue\n",
        "\n",
        "    partes = linea.split(\"\\t\")\n",
        "    if len(partes) < 3:\n",
        "        continue\n",
        "\n",
        "    clave = partes[0]\n",
        "    try:\n",
        "        goles = int(partes[1])\n",
        "        partidos = int(partes[2])\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "    if clave_actual is None:\n",
        "        clave_actual = clave\n",
        "        goles_acum = goles\n",
        "        partidos_acum = partidos\n",
        "        continue\n",
        "\n",
        "    if clave == clave_actual:\n",
        "        goles_acum += goles\n",
        "        partidos_acum += partidos\n",
        "    else:\n",
        "        emitir_resultado(clave_actual, goles_acum, partidos_acum)\n",
        "        clave_actual = clave\n",
        "        goles_acum = goles\n",
        "        partidos_acum = partidos\n",
        "\n",
        "if clave_actual is not None:\n",
        "    emitir_resultado(clave_actual, goles_acum, partidos_acum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP6r_cRzlTjJ",
        "outputId": "62efdb40-74a0-4798-ead5-0c7911568e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reducerMediaGolesPartido.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Permisos de ejecución\n",
        "Dar permisos al usuario de consola para ejecutar cada archivo."
      ],
      "metadata": {
        "id": "lHiEALnvm9nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod u+x mapperMediaGolesPartido.py\n",
        "!chmod u+x combinerMediaGolesPartido.py\n",
        "!chmod u+x reducerMediaGolesPartido.py"
      ],
      "metadata": {
        "id": "kWA735ucm8MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Hadoop Streaming**\n",
        "Se fuerza 1 reducer para que la salida mantenga el orden global por clave (alfabético)."
      ],
      "metadata": {
        "id": "YnOCPwdjlUDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf salidaMediaGolesPartido\n",
        "\n",
        "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.4.2.jar \\\n",
        "  -D mapreduce.job.reduces=1 \\\n",
        "  -file ./mapperMediaGolesPartido.py -mapper ./mapperMediaGolesPartido.py \\\n",
        "  -file ./combinerMediaGolesPartido.py -combiner ./combinerMediaGolesPartido.py \\\n",
        "  -file ./reducerMediaGolesPartido.py -reducer ./reducerMediaGolesPartido.py \\\n",
        "  -input resultados_futbol.csv -output ./salidaMediaGolesPartido\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SahKjgdzoEeM",
        "outputId": "4fe3716b-cd1f-4657-f05e-4145b1237277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-11 15:54:04,322 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [./mapperMediaGolesPartido.py, ./combinerMediaGolesPartido.py, ./reducerMediaGolesPartido.py] [] /tmp/streamjob10531852711797292657.jar tmpDir=null\n",
            "2026-01-11 15:54:05,428 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2026-01-11 15:54:05,707 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2026-01-11 15:54:05,748 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2026-01-11 15:54:06,129 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local450223745_0001\n",
            "2026-01-11 15:54:06,131 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2026-01-11 15:54:06,578 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapperMediaGolesPartido.py as file:/tmp/hadoop-root/mapred/local/job_local450223745_0001_1bed036b-b388-4c54-ac4c-5ca9c9346b80/mapperMediaGolesPartido.py\n",
            "2026-01-11 15:54:06,629 INFO mapred.LocalDistributedCacheManager: Localized file:/content/combinerMediaGolesPartido.py as file:/tmp/hadoop-root/mapred/local/job_local450223745_0001_fa0ebb56-8fdb-4e34-b5b9-d6cac2e6e03d/combinerMediaGolesPartido.py\n",
            "2026-01-11 15:54:06,632 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducerMediaGolesPartido.py as file:/tmp/hadoop-root/mapred/local/job_local450223745_0001_7662b7dd-e796-458a-a726-9e4fed5ae322/reducerMediaGolesPartido.py\n",
            "2026-01-11 15:54:06,755 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2026-01-11 15:54:06,759 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2026-01-11 15:54:06,761 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2026-01-11 15:54:06,761 INFO mapreduce.Job: Running job: job_local450223745_0001\n",
            "2026-01-11 15:54:06,773 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2026-01-11 15:54:06,773 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2026-01-11 15:54:06,826 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2026-01-11 15:54:06,830 INFO mapred.LocalJobRunner: Starting task: attempt_local450223745_0001_m_000000_0\n",
            "2026-01-11 15:54:06,867 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2026-01-11 15:54:06,867 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2026-01-11 15:54:06,893 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2026-01-11 15:54:06,908 INFO mapred.MapTask: Processing split: file:/content/resultados_futbol.csv:0+569436\n",
            "2026-01-11 15:54:06,937 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2026-01-11 15:54:07,022 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2026-01-11 15:54:07,022 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2026-01-11 15:54:07,022 INFO mapred.MapTask: soft limit at 83886080\n",
            "2026-01-11 15:54:07,022 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2026-01-11 15:54:07,022 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2026-01-11 15:54:07,027 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2026-01-11 15:54:07,037 INFO streaming.PipeMapRed: PipeMapRed exec [/content/./mapperMediaGolesPartido.py]\n",
            "2026-01-11 15:54:07,051 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2026-01-11 15:54:07,069 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2026-01-11 15:54:07,070 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2026-01-11 15:54:07,072 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2026-01-11 15:54:07,073 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2026-01-11 15:54:07,073 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2026-01-11 15:54:07,078 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2026-01-11 15:54:07,079 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2026-01-11 15:54:07,079 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2026-01-11 15:54:07,080 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2026-01-11 15:54:07,081 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2026-01-11 15:54:07,082 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2026-01-11 15:54:07,129 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,131 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,135 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,169 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,232 INFO streaming.PipeMapRed: Records R/W=2064/1\n",
            "2026-01-11 15:54:07,396 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2026-01-11 15:54:07,396 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2026-01-11 15:54:07,402 INFO mapred.LocalJobRunner: \n",
            "2026-01-11 15:54:07,403 INFO mapred.MapTask: Starting flush of map output\n",
            "2026-01-11 15:54:07,403 INFO mapred.MapTask: Spilling map output\n",
            "2026-01-11 15:54:07,403 INFO mapred.MapTask: bufstart = 0; bufend = 395771; bufvoid = 104857600\n",
            "2026-01-11 15:54:07,403 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26141440(104565760); length = 72957/6553600\n",
            "2026-01-11 15:54:07,487 INFO streaming.PipeMapRed: PipeMapRed exec [/content/./combinerMediaGolesPartido.py]\n",
            "2026-01-11 15:54:07,495 INFO Configuration.deprecation: mapred.skip.map.auto.incr.proc.count is deprecated. Instead, use mapreduce.map.skip.proc-count.auto-incr\n",
            "2026-01-11 15:54:07,523 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,524 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,525 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,539 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,597 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,632 INFO streaming.PipeMapRed: Records R/W=18240/1\n",
            "2026-01-11 15:54:07,656 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2026-01-11 15:54:07,658 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2026-01-11 15:54:07,658 INFO mapred.MapTask: Finished spill 0\n",
            "2026-01-11 15:54:07,676 INFO mapred.Task: Task:attempt_local450223745_0001_m_000000_0 is done. And is in the process of committing\n",
            "2026-01-11 15:54:07,679 INFO mapred.LocalJobRunner: Records R/W=18240/1\n",
            "2026-01-11 15:54:07,679 INFO mapred.Task: Task 'attempt_local450223745_0001_m_000000_0' done.\n",
            "2026-01-11 15:54:07,689 INFO mapred.Task: Final Counters for attempt_local450223745_0001_m_000000_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=574628\n",
            "\t\tFILE: Number of bytes written=726017\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=9121\n",
            "\t\tMap output records=18240\n",
            "\t\tMap output bytes=395771\n",
            "\t\tMap output materialized bytes=2401\n",
            "\t\tInput split bytes=87\n",
            "\t\tCombine input records=18240\n",
            "\t\tCombine output records=88\n",
            "\t\tSpilled Records=88\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=15\n",
            "\t\tTotal committed heap usage (bytes)=304087040\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=569436\n",
            "2026-01-11 15:54:07,689 INFO mapred.LocalJobRunner: Finishing task: attempt_local450223745_0001_m_000000_0\n",
            "2026-01-11 15:54:07,690 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2026-01-11 15:54:07,695 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2026-01-11 15:54:07,696 INFO mapred.LocalJobRunner: Starting task: attempt_local450223745_0001_r_000000_0\n",
            "2026-01-11 15:54:07,710 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2026-01-11 15:54:07,711 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2026-01-11 15:54:07,712 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2026-01-11 15:54:07,720 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3fd3b104\n",
            "2026-01-11 15:54:07,724 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2026-01-11 15:54:07,754 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2381106432, maxSingleShuffleLimit=595276608, mergeThreshold=1571530368, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2026-01-11 15:54:07,759 INFO reduce.EventFetcher: attempt_local450223745_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2026-01-11 15:54:07,773 INFO mapreduce.Job: Job job_local450223745_0001 running in uber mode : false\n",
            "2026-01-11 15:54:07,775 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2026-01-11 15:54:07,811 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local450223745_0001_m_000000_0 decomp: 2397 len: 2401 to MEMORY\n",
            "2026-01-11 15:54:07,816 INFO reduce.InMemoryMapOutput: Read 2397 bytes from map-output for attempt_local450223745_0001_m_000000_0\n",
            "2026-01-11 15:54:07,819 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2397, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2397\n",
            "2026-01-11 15:54:07,823 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2026-01-11 15:54:07,824 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2026-01-11 15:54:07,825 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2026-01-11 15:54:07,841 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2026-01-11 15:54:07,842 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2381 bytes\n",
            "2026-01-11 15:54:07,846 INFO reduce.MergeManagerImpl: Merged 1 segments, 2397 bytes to disk to satisfy reduce memory limit\n",
            "2026-01-11 15:54:07,848 INFO reduce.MergeManagerImpl: Merging 1 files, 2401 bytes from disk\n",
            "2026-01-11 15:54:07,850 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2026-01-11 15:54:07,852 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2026-01-11 15:54:07,855 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2381 bytes\n",
            "2026-01-11 15:54:07,856 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2026-01-11 15:54:07,862 INFO streaming.PipeMapRed: PipeMapRed exec [/content/./reducerMediaGolesPartido.py]\n",
            "2026-01-11 15:54:07,868 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2026-01-11 15:54:07,874 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2026-01-11 15:54:07,908 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,910 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2026-01-11 15:54:07,958 INFO streaming.PipeMapRed: Records R/W=88/1\n",
            "2026-01-11 15:54:07,966 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2026-01-11 15:54:07,969 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2026-01-11 15:54:07,971 INFO mapred.Task: Task:attempt_local450223745_0001_r_000000_0 is done. And is in the process of committing\n",
            "2026-01-11 15:54:07,975 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2026-01-11 15:54:07,977 INFO mapred.Task: Task attempt_local450223745_0001_r_000000_0 is allowed to commit now\n",
            "2026-01-11 15:54:07,984 INFO output.FileOutputCommitter: Saved output of task 'attempt_local450223745_0001_r_000000_0' to file:/content/salidaMediaGolesPartido\n",
            "2026-01-11 15:54:07,990 INFO mapred.LocalJobRunner: Records R/W=88/1 > reduce\n",
            "2026-01-11 15:54:07,990 INFO mapred.Task: Task 'attempt_local450223745_0001_r_000000_0' done.\n",
            "2026-01-11 15:54:07,991 INFO mapred.Task: Final Counters for attempt_local450223745_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=579462\n",
            "\t\tFILE: Number of bytes written=730292\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=88\n",
            "\t\tReduce shuffle bytes=2401\n",
            "\t\tReduce input records=88\n",
            "\t\tReduce output records=88\n",
            "\t\tSpilled Records=88\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=304087040\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=1874\n",
            "2026-01-11 15:54:07,993 INFO mapred.LocalJobRunner: Finishing task: attempt_local450223745_0001_r_000000_0\n",
            "2026-01-11 15:54:07,993 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2026-01-11 15:54:08,779 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2026-01-11 15:54:08,779 INFO mapreduce.Job: Job job_local450223745_0001 completed successfully\n",
            "2026-01-11 15:54:08,796 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1154090\n",
            "\t\tFILE: Number of bytes written=1456309\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=9121\n",
            "\t\tMap output records=18240\n",
            "\t\tMap output bytes=395771\n",
            "\t\tMap output materialized bytes=2401\n",
            "\t\tInput split bytes=87\n",
            "\t\tCombine input records=18240\n",
            "\t\tCombine output records=88\n",
            "\t\tReduce input groups=88\n",
            "\t\tReduce shuffle bytes=2401\n",
            "\t\tReduce input records=88\n",
            "\t\tReduce output records=88\n",
            "\t\tSpilled Records=176\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=15\n",
            "\t\tTotal committed heap usage (bytes)=608174080\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=569436\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=1874\n",
            "2026-01-11 15:54:08,796 INFO streaming.StreamJob: Output directory: ./salidaMediaGolesPartido\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ./salidaMediaGolesPartido/part-*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1Na4do-oGhZ",
        "outputId": "aef9a250-d5de-46c1-9029-3dd9b02a4af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alavés;Local;1\t\n",
            "Alavés;Visitante;1\t\n",
            "Albacete;Local;1\t\n",
            "Albacete;Visitante;1\t\n",
            "Almería;Local;1\t\n",
            "Almería;Visitante;1\t\n",
            "Athletic;Local;1\t\n",
            "Athletic;Visitante;1\t\n",
            "Atlético;Local;2\t\n",
            "Atlético;Visitante;1\t\n",
            "Barcelona;Local;3\t\n",
            "Barcelona;Visitante;2\t\n",
            "Celta;Local;1\t\n",
            "Celta;Visitante;1\t\n",
            "Cádiz;Local;1\t\n",
            "Cádiz;Visitante;1\t\n",
            "Córdoba;Local;1\t\n",
            "Córdoba;Visitante;1\t\n",
            "Deportivo Alavés;Local;1\t\n",
            "Deportivo Alavés;Visitante;1\t\n",
            "Deportivo;Local;2\t\n",
            "Deportivo;Visitante;1\t\n",
            "Eibar;Local;1\t\n",
            "Eibar;Visitante;1\t\n",
            "Elche;Local;1\t\n",
            "Elche;Visitante;1\t\n",
            "Espanyol;Local;1\t\n",
            "Espanyol;Visitante;1\t\n",
            "Getafe;Local;1\t\n",
            "Getafe;Visitante;1\t\n",
            "Gimnàstic Tarragona;Local;1\t\n",
            "Gimnàstic Tarragona;Visitante;1\t\n",
            "Girona;Local;1\t\n",
            "Girona;Visitante;1\t\n",
            "Granada;Local;1\t\n",
            "Granada;Visitante;1\t\n",
            "Huesca;Local;1\t\n",
            "Huesca;Visitante;1\t\n",
            "Hércules;Local;1\t\n",
            "Hércules;Visitante;0\t\n",
            "Las Palmas;Local;1\t\n",
            "Las Palmas;Visitante;1\t\n",
            "Leganés;Local;1\t\n",
            "Leganés;Visitante;1\t\n",
            "Levante;Local;1\t\n",
            "Levante;Visitante;1\t\n",
            "Mallorca;Local;1\t\n",
            "Mallorca;Visitante;1\t\n",
            "Málaga;Local;1\t\n",
            "Málaga;Visitante;1\t\n",
            "Numancia;Local;1\t\n",
            "Numancia;Visitante;1\t\n",
            "Osasuna;Local;1\t\n",
            "Osasuna;Visitante;1\t\n",
            "R. Sociedad;Local;2\t\n",
            "R. Sociedad;Visitante;1\t\n",
            "Racing;Local;1\t\n",
            "Racing;Visitante;1\t\n",
            "Rayo Vallecano;Local;1\t\n",
            "Rayo Vallecano;Visitante;1\t\n",
            "Real Betis;Local;1\t\n",
            "Real Betis;Visitante;1\t\n",
            "Real Madrid;Local;3\t\n",
            "Real Madrid;Visitante;2\t\n",
            "Real Murcia;Local;1\t\n",
            "Real Murcia;Visitante;1\t\n",
            "Real Oviedo;Local;2\t\n",
            "Real Oviedo;Visitante;1\t\n",
            "Real Sociedad;Local;1\t\n",
            "Real Sociedad;Visitante;1\t\n",
            "Real Sporting;Local;1\t\n",
            "Real Sporting;Visitante;1\t\n",
            "Real Valladolid;Local;1\t\n",
            "Real Valladolid;Visitante;1\t\n",
            "Real Zaragoza;Local;2\t\n",
            "Real Zaragoza;Visitante;1\t\n",
            "Recreativo;Local;1\t\n",
            "Recreativo;Visitante;1\t\n",
            "Sevilla;Local;2\t\n",
            "Sevilla;Visitante;1\t\n",
            "Tenerife;Local;1\t\n",
            "Tenerife;Visitante;1\t\n",
            "Valencia;Local;2\t\n",
            "Valencia;Visitante;1\t\n",
            "Villarreal;Local;2\t\n",
            "Villarreal;Visitante;1\t\n",
            "Xerez;Local;1\t\n",
            "Xerez;Visitante;1\t\n"
          ]
        }
      ]
    }
  ]
}